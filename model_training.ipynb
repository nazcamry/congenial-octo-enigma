{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5cd2a1b-4d8c-4fe2-8fcb-3cd8b16c52c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ò–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n",
      "‚úÖ –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ WMAE –≥–æ—Ç–æ–≤—ã\n"
     ]
    }
   ],
   "source": [
    "# –ë–õ–û–ö 1: –ò–ú–ü–û–†–¢–´ –ò –ö–ê–°–¢–û–ú–ù–´–ï –ú–ï–¢–†–ò–ö–ò\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "import optuna\n",
    "import shap\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ –ò–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
    "\n",
    "# ==================================================================================\n",
    "# –ö–ê–°–¢–û–ú–ù–ê–Ø –ú–ï–¢–†–ò–ö–ê WMAE\n",
    "# ==================================================================================\n",
    "\n",
    "def wmae_metric(y_true, y_pred, weights):\n",
    "    \"\"\"Weighted Mean Absolute Error\"\"\"\n",
    "    return np.average(np.abs(y_true - y_pred), weights=weights)\n",
    "\n",
    "def wmae_catboost(y_pred, data):\n",
    "    \"\"\"WMAE –¥–ª—è CatBoost\"\"\"\n",
    "    y_true = data.get_label()\n",
    "    weights = data.get_weight()\n",
    "    return 'WMAE', wmae_metric(y_true, y_pred, weights)\n",
    "\n",
    "def wmae_lgb(y_pred, data):\n",
    "    \"\"\"WMAE –¥–ª—è LightGBM\"\"\"\n",
    "    y_true = data.get_label()\n",
    "    weights = data.get_weight()\n",
    "    return 'WMAE', wmae_metric(y_true, y_pred, weights), False\n",
    "\n",
    "def wmae_xgb(y_pred, dtrain):\n",
    "    \"\"\"WMAE –¥–ª—è XGBoost\"\"\"\n",
    "    y_true = dtrain.get_label()\n",
    "    weights = dtrain.get_weight()\n",
    "    return 'WMAE', wmae_metric(y_true, y_pred, weights)\n",
    "\n",
    "print(\"‚úÖ –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ WMAE –≥–æ—Ç–æ–≤—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a9c643-eb29-45aa-9a51-95fab66f14aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞...\n",
      "‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: 162 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, 76786 —Å—Ç—Ä–æ–∫\n"
     ]
    }
   ],
   "source": [
    "#  –ë–õ–û–ö 2: –ó–ê–ì–†–£–ó–ö–ê –ß–ï–ö–ü–û–ò–ù–¢–ê\n",
    "\n",
    "# ==================================================================================\n",
    "# –ó–ê–ì–†–£–ó–ö–ê –ü–û–î–ì–û–¢–û–í–õ–ï–ù–ù–´–• –î–ê–ù–ù–´–•\n",
    "# ==================================================================================\n",
    "\n",
    "checkpoint_file = 'data_checkpoint.pkl'\n",
    "\n",
    "print(\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞...\")\n",
    "\n",
    "with open(checkpoint_file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_final = data['X_final']\n",
    "X_test_final = data['X_test_final']\n",
    "X_lgb = data['X_lgb']\n",
    "X_test_lgb = data['X_test_lgb']\n",
    "X_xgb = data['X_xgb']\n",
    "X_test_xgb = data['X_test_xgb']\n",
    "y_log = data['y_log']\n",
    "w = data['w']\n",
    "cat_final = data['cat_final']\n",
    "test_ids = data['test_ids']\n",
    "\n",
    "print(f\"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {X_final.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, {len(X_final)} —Å—Ç—Ä–æ–∫\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4f19663-4b08-44de-8970-ed28373cdb86",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 18:35:34,029] A new study created in memory with name: catboost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç BAYESIAN OPTIMIZATION (50 –∏—Ç–µ—Ä–∞—Ü–∏–π –Ω–∞ –º–æ–¥–µ–ª—å)...\n",
      "–≠—Ç–æ –∑–∞–π–º—ë—Ç ~30-60 –º–∏–Ω—É—Ç, –Ω–æ –Ω–∞–π–¥—ë—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã!\n",
      "\n",
      "üê± –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è CatBoost...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a0f7db36614df191305cb18341db6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 18:36:46,108] Trial 0 finished with value: 65751.2582462182 and parameters: {'iterations': 1825, 'learning_rate': 0.03983964846389411, 'depth': 4, 'l2_leaf_reg': 1.5343353120023513, 'random_strength': 1.4928515605716097, 'bagging_temperature': 0.5039218772736574}. Best is trial 0 with value: 65751.2582462182.\n",
      "[I 2025-11-29 18:39:11,454] Trial 1 finished with value: 66626.18286386097 and parameters: {'iterations': 1519, 'learning_rate': 0.012497716186167771, 'depth': 8, 'l2_leaf_reg': 1.5516399865149908, 'random_strength': 4.763037387425909, 'bagging_temperature': 0.5233921641301655}. Best is trial 0 with value: 65751.2582462182.\n",
      "[I 2025-11-29 18:41:22,291] Trial 2 finished with value: 65112.05155523218 and parameters: {'iterations': 1659, 'learning_rate': 0.03950711162206714, 'depth': 7, 'l2_leaf_reg': 3.185644576142434, 'random_strength': 2.9556983584188314, 'bagging_temperature': 0.21434975246953492}. Best is trial 2 with value: 65112.05155523218.\n",
      "[I 2025-11-29 18:45:43,806] Trial 3 finished with value: 65566.77913073957 and parameters: {'iterations': 2753, 'learning_rate': 0.013446742934048931, 'depth': 8, 'l2_leaf_reg': 5.072429858424572, 'random_strength': 3.4312455138660596, 'bagging_temperature': 0.6742277646883502}. Best is trial 2 with value: 65112.05155523218.\n",
      "[I 2025-11-29 18:47:53,911] Trial 4 finished with value: 65806.46744263645 and parameters: {'iterations': 2642, 'learning_rate': 0.01414468126767163, 'depth': 5, 'l2_leaf_reg': 3.9391862585241815, 'random_strength': 1.3373396582227415, 'bagging_temperature': 0.07122180710433546}. Best is trial 2 with value: 65112.05155523218.\n",
      "[I 2025-11-29 18:49:51,691] Trial 5 finished with value: 66356.9067600753 and parameters: {'iterations': 1912, 'learning_rate': 0.010286981154988384, 'depth': 6, 'l2_leaf_reg': 3.6180386111645175, 'random_strength': 0.46398320158398676, 'bagging_temperature': 0.24668414684046924}. Best is trial 2 with value: 65112.05155523218.\n",
      "[I 2025-11-29 18:54:41,031] Trial 6 finished with value: 65243.4863110192 and parameters: {'iterations': 2993, 'learning_rate': 0.01639101573959986, 'depth': 8, 'l2_leaf_reg': 9.079890597834812, 'random_strength': 0.4718646352242889, 'bagging_temperature': 0.791380512673476}. Best is trial 2 with value: 65112.05155523218.\n",
      "[I 2025-11-29 18:57:06,666] Trial 7 finished with value: 65260.9367191408 and parameters: {'iterations': 1844, 'learning_rate': 0.02469893697205994, 'depth': 7, 'l2_leaf_reg': 1.753920843189689, 'random_strength': 3.5780697334403504, 'bagging_temperature': 0.4531377463437001}. Best is trial 2 with value: 65112.05155523218.\n",
      "[I 2025-11-29 18:58:47,434] Trial 8 finished with value: 65136.448167072966 and parameters: {'iterations': 1597, 'learning_rate': 0.029026822870561467, 'depth': 6, 'l2_leaf_reg': 5.887566077750487, 'random_strength': 1.7200572755932493, 'bagging_temperature': 0.5340051441582486}. Best is trial 2 with value: 65112.05155523218.\n",
      "[I 2025-11-29 19:02:38,964] Trial 9 finished with value: 65123.28170164151 and parameters: {'iterations': 2997, 'learning_rate': 0.034188897246887326, 'depth': 7, 'l2_leaf_reg': 7.4063432302629515, 'random_strength': 4.1406883693414755, 'bagging_temperature': 0.2640196741105454}. Best is trial 2 with value: 65112.05155523218.\n",
      "[I 2025-11-29 19:04:33,257] Trial 10 finished with value: 64922.557233818516 and parameters: {'iterations': 2246, 'learning_rate': 0.04583933504183867, 'depth': 5, 'l2_leaf_reg': 3.389919229159831, 'random_strength': 2.58332242724028, 'bagging_temperature': 0.03511068353377653}. Best is trial 10 with value: 64922.557233818516.\n",
      "[I 2025-11-29 19:06:26,599] Trial 11 finished with value: 64966.09836662099 and parameters: {'iterations': 2210, 'learning_rate': 0.04980690837848048, 'depth': 5, 'l2_leaf_reg': 3.4194328580223052, 'random_strength': 2.484807497665796, 'bagging_temperature': 0.0077946249977449734}. Best is trial 10 with value: 64922.557233818516.\n",
      "[I 2025-11-29 19:07:55,085] Trial 12 finished with value: 65414.468755171634 and parameters: {'iterations': 2259, 'learning_rate': 0.04826761931450928, 'depth': 4, 'l2_leaf_reg': 5.25222462365681, 'random_strength': 2.3644146139750166, 'bagging_temperature': 0.005814625620588321}. Best is trial 10 with value: 64922.557233818516.\n",
      "[I 2025-11-29 19:09:49,002] Trial 13 finished with value: 65623.1163124748 and parameters: {'iterations': 2244, 'learning_rate': 0.020359248924035272, 'depth': 5, 'l2_leaf_reg': 2.925957384050159, 'random_strength': 2.355027410228094, 'bagging_temperature': 0.14164602657311787}. Best is trial 10 with value: 64922.557233818516.\n",
      "[I 2025-11-29 19:11:40,238] Trial 14 finished with value: 64995.46924186672 and parameters: {'iterations': 2185, 'learning_rate': 0.04980005352675307, 'depth': 5, 'l2_leaf_reg': 6.451961299933253, 'random_strength': 2.8717380738420752, 'bagging_temperature': 0.9426278584794683}. Best is trial 10 with value: 64922.557233818516.\n",
      "[I 2025-11-29 19:13:44,675] Trial 15 finished with value: 65016.091538784945 and parameters: {'iterations': 2433, 'learning_rate': 0.03290648280080463, 'depth': 5, 'l2_leaf_reg': 4.431792613548132, 'random_strength': 2.156756703933594, 'bagging_temperature': 0.34847845519763243}. Best is trial 10 with value: 64922.557233818516.\n",
      "[I 2025-11-29 19:15:56,876] Trial 16 finished with value: 64918.650174117596 and parameters: {'iterations': 2039, 'learning_rate': 0.039674457999750376, 'depth': 6, 'l2_leaf_reg': 2.492743207082224, 'random_strength': 1.0381183549332718, 'bagging_temperature': 0.0032066127469761938}. Best is trial 16 with value: 64918.650174117596.\n",
      "[I 2025-11-29 19:18:06,169] Trial 17 finished with value: 65075.383317346954 and parameters: {'iterations': 2013, 'learning_rate': 0.023615484400428256, 'depth': 6, 'l2_leaf_reg': 2.5263173519118416, 'random_strength': 0.9797222826997356, 'bagging_temperature': 0.1150224400027898}. Best is trial 16 with value: 64918.650174117596.\n",
      "[I 2025-11-29 19:19:43,257] Trial 18 finished with value: 65458.110195942456 and parameters: {'iterations': 2523, 'learning_rate': 0.038949169992154635, 'depth': 4, 'l2_leaf_reg': 2.337892968026793, 'random_strength': 0.08529235980758476, 'bagging_temperature': 0.304362284015846}. Best is trial 16 with value: 64918.650174117596.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 19:21:53,394] A new study created in memory with name: lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 19:21:53,392] Trial 19 finished with value: 65007.47230321282 and parameters: {'iterations': 2042, 'learning_rate': 0.027306319813795773, 'depth': 6, 'l2_leaf_reg': 7.208187523927009, 'random_strength': 1.0481275347710937, 'bagging_temperature': 0.41117111965088515}. Best is trial 16 with value: 64918.650174117596.\n",
      "   –õ—É—á—à–∏–π WMAE: 64918.65\n",
      "   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {'iterations': 2039, 'learning_rate': 0.039674457999750376, 'depth': 6, 'l2_leaf_reg': 2.492743207082224, 'random_strength': 1.0381183549332718, 'bagging_temperature': 0.0032066127469761938}\n",
      "\n",
      "üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è LightGBM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f050031d5a402691153077051780c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[946]\tvalid_0's l1: 0.419944\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1025]\tvalid_0's l1: 0.414276\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1470]\tvalid_0's l1: 0.417318\n",
      "[I 2025-11-29 19:22:52,676] Trial 0 finished with value: 62265.56278327408 and parameters: {'learning_rate': 0.02354411384047293, 'num_leaves': 124, 'max_depth': 14, 'feature_fraction': 0.7679002176117616, 'bagging_fraction': 0.8792039897732091, 'bagging_freq': 7, 'min_child_samples': 35, 'lambda_l1': 3.664664863194461, 'lambda_l2': 1.098204286612604}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[619]\tvalid_0's l1: 0.423829\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[912]\tvalid_0's l1: 0.420215\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[527]\tvalid_0's l1: 0.423167\n",
      "[I 2025-11-29 19:23:22,844] Trial 1 finished with value: 62994.93653323411 and parameters: {'learning_rate': 0.05150340174849425, 'num_leaves': 84, 'max_depth': 14, 'feature_fraction': 0.7407688835628398, 'bagging_fraction': 0.6701967529296644, 'bagging_freq': 5, 'min_child_samples': 13, 'lambda_l1': 1.2283081939944995, 'lambda_l2': 7.369921320024294}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1038]\tvalid_0's l1: 0.431502\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[976]\tvalid_0's l1: 0.425562\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1093]\tvalid_0's l1: 0.429121\n",
      "[I 2025-11-29 19:23:55,957] Trial 2 finished with value: 63930.576015191444 and parameters: {'learning_rate': 0.047221125652724176, 'num_leaves': 77, 'max_depth': 8, 'feature_fraction': 0.8872635863004068, 'bagging_fraction': 0.5797242708932928, 'bagging_freq': 2, 'min_child_samples': 25, 'lambda_l1': 1.6942104681400127, 'lambda_l2': 2.408082390592581}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 0.420843\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 0.415252\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tvalid_0's l1: 0.418784\n",
      "[I 2025-11-29 19:25:00,396] Trial 3 finished with value: 62342.95262887818 and parameters: {'learning_rate': 0.01261735995559417, 'num_leaves': 68, 'max_depth': 12, 'feature_fraction': 0.6038222930460518, 'bagging_fraction': 0.7721637798768247, 'bagging_freq': 5, 'min_child_samples': 36, 'lambda_l1': 6.435610577422319, 'lambda_l2': 2.2855706929139674}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1461]\tvalid_0's l1: 0.434835\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[589]\tvalid_0's l1: 0.428723\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1340]\tvalid_0's l1: 0.430493\n",
      "[I 2025-11-29 19:25:25,476] Trial 4 finished with value: 64426.73818360808 and parameters: {'learning_rate': 0.0867479996756341, 'num_leaves': 31, 'max_depth': 9, 'feature_fraction': 0.5085009225108137, 'bagging_fraction': 0.5439531901526707, 'bagging_freq': 4, 'min_child_samples': 49, 'lambda_l1': 4.048686472719405, 'lambda_l2': 7.665441761567844}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1818]\tvalid_0's l1: 0.425402\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1647]\tvalid_0's l1: 0.418615\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1997]\tvalid_0's l1: 0.421569\n",
      "[I 2025-11-29 19:26:19,397] Trial 5 finished with value: 62993.87620430001 and parameters: {'learning_rate': 0.02220672936557275, 'num_leaves': 60, 'max_depth': 11, 'feature_fraction': 0.7110981925967856, 'bagging_fraction': 0.5171827358870607, 'bagging_freq': 2, 'min_child_samples': 12, 'lambda_l1': 2.9009664716764227, 'lambda_l2': 2.2069814709497737}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 0.429961\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 0.423058\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 0.426641\n",
      "[I 2025-11-29 19:27:01,699] Trial 6 finished with value: 63487.20990446723 and parameters: {'learning_rate': 0.010330276957743665, 'num_leaves': 35, 'max_depth': 9, 'feature_fraction': 0.5149189423151613, 'bagging_fraction': 0.5586357960731254, 'bagging_freq': 3, 'min_child_samples': 8, 'lambda_l1': 6.443831980192715, 'lambda_l2': 2.821840081187814}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[401]\tvalid_0's l1: 0.430691\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[451]\tvalid_0's l1: 0.42254\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[445]\tvalid_0's l1: 0.427279\n",
      "[I 2025-11-29 19:27:23,234] Trial 7 finished with value: 63799.90323975156 and parameters: {'learning_rate': 0.08245336027639745, 'num_leaves': 75, 'max_depth': 10, 'feature_fraction': 0.8735671471478107, 'bagging_fraction': 0.8625238195202498, 'bagging_freq': 2, 'min_child_samples': 11, 'lambda_l1': 5.5874459723145335, 'lambda_l2': 9.049049159901541}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[571]\tvalid_0's l1: 0.426191\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[844]\tvalid_0's l1: 0.421356\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[966]\tvalid_0's l1: 0.424358\n",
      "[I 2025-11-29 19:28:01,215] Trial 8 finished with value: 63027.75877369821 and parameters: {'learning_rate': 0.07702343554174983, 'num_leaves': 63, 'max_depth': 15, 'feature_fraction': 0.8314934680890682, 'bagging_fraction': 0.8937994231845764, 'bagging_freq': 4, 'min_child_samples': 41, 'lambda_l1': 0.7947742633618649, 'lambda_l2': 5.61086518130676}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1176]\tvalid_0's l1: 0.423616\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[678]\tvalid_0's l1: 0.419172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[950]\tvalid_0's l1: 0.422039\n",
      "[I 2025-11-29 19:28:38,927] Trial 9 finished with value: 63400.00204681468 and parameters: {'learning_rate': 0.03762661137164637, 'num_leaves': 125, 'max_depth': 13, 'feature_fraction': 0.568467121500202, 'bagging_fraction': 0.560051442598908, 'bagging_freq': 3, 'min_child_samples': 36, 'lambda_l1': 1.0070372800758998, 'lambda_l2': 7.759242039257465}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1220]\tvalid_0's l1: 0.419949\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[880]\tvalid_0's l1: 0.413588\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1998]\tvalid_0's l1: 0.416051\n",
      "[I 2025-11-29 19:29:42,358] Trial 10 finished with value: 62282.28650005177 and parameters: {'learning_rate': 0.021119065372330822, 'num_leaves': 123, 'max_depth': 15, 'feature_fraction': 0.7769870728440268, 'bagging_fraction': 0.7857975916945619, 'bagging_freq': 7, 'min_child_samples': 24, 'lambda_l1': 9.354132642896397, 'lambda_l2': 0.19030719164105991}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1249]\tvalid_0's l1: 0.419678\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[945]\tvalid_0's l1: 0.413031\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1557]\tvalid_0's l1: 0.416463\n",
      "[I 2025-11-29 19:30:42,751] Trial 11 finished with value: 62276.73848570116 and parameters: {'learning_rate': 0.021543594591265695, 'num_leaves': 126, 'max_depth': 15, 'feature_fraction': 0.774025512317533, 'bagging_fraction': 0.7987991940295041, 'bagging_freq': 7, 'min_child_samples': 24, 'lambda_l1': 8.27294403797633, 'lambda_l2': 0.2722273491780778}. Best is trial 0 with value: 62265.56278327408.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1962]\tvalid_0's l1: 0.418576\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1412]\tvalid_0's l1: 0.413718\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1658]\tvalid_0's l1: 0.417355\n",
      "[I 2025-11-29 19:31:50,075] Trial 12 finished with value: 62233.34322834874 and parameters: {'learning_rate': 0.020986147307325755, 'num_leaves': 104, 'max_depth': 13, 'feature_fraction': 0.656292078984841, 'bagging_fraction': 0.8105694664142621, 'bagging_freq': 7, 'min_child_samples': 30, 'lambda_l1': 8.820281135732854, 'lambda_l2': 0.19129633550493752}. Best is trial 12 with value: 62233.34322834874.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1548]\tvalid_0's l1: 0.420966\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1929]\tvalid_0's l1: 0.413463\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 0.416196\n",
      "[I 2025-11-29 19:33:08,393] Trial 13 finished with value: 62342.66247294527 and parameters: {'learning_rate': 0.01610956467282253, 'num_leaves': 104, 'max_depth': 13, 'feature_fraction': 0.651100405898261, 'bagging_fraction': 0.8377170755270924, 'bagging_freq': 6, 'min_child_samples': 31, 'lambda_l1': 3.931920343169393, 'lambda_l2': 4.288820768396761}. Best is trial 12 with value: 62233.34322834874.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1743]\tvalid_0's l1: 0.419822\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1195]\tvalid_0's l1: 0.415889\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1426]\tvalid_0's l1: 0.418147\n",
      "[I 2025-11-29 19:34:03,760] Trial 14 finished with value: 62527.99774645731 and parameters: {'learning_rate': 0.028032946478801377, 'num_leaves': 104, 'max_depth': 13, 'feature_fraction': 0.6664874933799435, 'bagging_fraction': 0.720051498517818, 'bagging_freq': 6, 'min_child_samples': 45, 'lambda_l1': 7.977006988998497, 'lambda_l2': 1.0341674263275766}. Best is trial 12 with value: 62233.34322834874.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1427]\tvalid_0's l1: 0.421425\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1176]\tvalid_0's l1: 0.417153\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1077]\tvalid_0's l1: 0.419954\n",
      "[I 2025-11-29 19:34:51,626] Trial 15 finished with value: 62825.773433186456 and parameters: {'learning_rate': 0.029994663395643932, 'num_leaves': 106, 'max_depth': 12, 'feature_fraction': 0.6282662214134364, 'bagging_fraction': 0.7144071035127265, 'bagging_freq': 7, 'min_child_samples': 18, 'lambda_l1': 9.813467647046346, 'lambda_l2': 5.30024723674035}. Best is trial 12 with value: 62233.34322834874.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1363]\tvalid_0's l1: 0.420442\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1809]\tvalid_0's l1: 0.41387\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 0.417059\n",
      "[I 2025-11-29 19:36:11,552] Trial 16 finished with value: 62247.02566537329 and parameters: {'learning_rate': 0.016421039163943506, 'num_leaves': 93, 'max_depth': 14, 'feature_fraction': 0.7078362690414058, 'bagging_fraction': 0.8916760988641691, 'bagging_freq': 6, 'min_child_samples': 31, 'lambda_l1': 3.0197841454529435, 'lambda_l2': 3.4930736576115864}. Best is trial 12 with value: 62233.34322834874.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1412]\tvalid_0's l1: 0.419765\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1300]\tvalid_0's l1: 0.413841\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1230]\tvalid_0's l1: 0.417713\n",
      "[I 2025-11-29 19:37:09,912] Trial 17 finished with value: 62170.71526181195 and parameters: {'learning_rate': 0.0158614291366624, 'num_leaves': 93, 'max_depth': 14, 'feature_fraction': 0.7006576198474429, 'bagging_fraction': 0.8239219288397926, 'bagging_freq': 6, 'min_child_samples': 30, 'lambda_l1': 2.6556856514238656, 'lambda_l2': 4.290607521856232}. Best is trial 17 with value: 62170.71526181195.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1349]\tvalid_0's l1: 0.423541\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1597]\tvalid_0's l1: 0.415348\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1730]\tvalid_0's l1: 0.419639\n",
      "[I 2025-11-29 19:38:07,459] Trial 18 finished with value: 62619.61302836891 and parameters: {'learning_rate': 0.015493210664552528, 'num_leaves': 92, 'max_depth': 11, 'feature_fraction': 0.5713738458390903, 'bagging_fraction': 0.6395409567656025, 'bagging_freq': 5, 'min_child_samples': 20, 'lambda_l1': 0.041407572199849696, 'lambda_l2': 6.0414621405245335}. Best is trial 17 with value: 62170.71526181195.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tvalid_0's l1: 0.418529\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1746]\tvalid_0's l1: 0.412582\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1998]\tvalid_0's l1: 0.416262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 19:39:27,693] A new study created in memory with name: xgboost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 19:39:27,690] Trial 19 finished with value: 62187.80016026421 and parameters: {'learning_rate': 0.011984839330405488, 'num_leaves': 111, 'max_depth': 13, 'feature_fraction': 0.6728789330541666, 'bagging_fraction': 0.8276969219042319, 'bagging_freq': 6, 'min_child_samples': 29, 'lambda_l1': 5.425240634451687, 'lambda_l2': 4.163456419631878}. Best is trial 17 with value: 62170.71526181195.\n",
      "   –õ—É—á—à–∏–π WMAE: 62170.72\n",
      "   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {'learning_rate': 0.0158614291366624, 'num_leaves': 93, 'max_depth': 14, 'feature_fraction': 0.7006576198474429, 'bagging_fraction': 0.8239219288397926, 'bagging_freq': 6, 'min_child_samples': 30, 'lambda_l1': 2.6556856514238656, 'lambda_l2': 4.290607521856232}\n",
      "\n",
      "‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è XGBoost...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668d55af15074f30b3a1613a36399a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 19:40:24,210] Trial 0 finished with value: 62496.861326348095 and parameters: {'learning_rate': 0.011633529763994796, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.8382566043855415, 'colsample_bytree': 0.6868297542668472, 'gamma': 0.1559836220866534, 'reg_alpha': 2.3039910053801957, 'reg_lambda': 1.7440519502839336}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:40:50,872] Trial 1 finished with value: 63590.51931157268 and parameters: {'learning_rate': 0.07158741213442271, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.8425427447838256, 'colsample_bytree': 0.7640667380862183, 'gamma': 2.141271639826088, 'reg_alpha': 6.793597699250524, 'reg_lambda': 7.967237807011685}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:41:23,809] Trial 2 finished with value: 63390.148536887544 and parameters: {'learning_rate': 0.06255003512687704, 'max_depth': 11, 'min_child_weight': 7, 'subsample': 0.8038250278968775, 'colsample_bytree': 0.8147347272223125, 'gamma': 3.251663048067547, 'reg_alpha': 3.901107657070809, 'reg_lambda': 1.3805395085403915}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:41:55,189] Trial 3 finished with value: 63574.25902016688 and parameters: {'learning_rate': 0.05895034319311461, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.8977493358404116, 'colsample_bytree': 0.6575584639012197, 'gamma': 0.3035961045275204, 'reg_alpha': 5.516725279625002, 'reg_lambda': 9.87784726038515}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:42:53,730] Trial 4 finished with value: 62702.006353631885 and parameters: {'learning_rate': 0.02384708405221663, 'max_depth': 12, 'min_child_weight': 7, 'subsample': 0.7746007505530939, 'colsample_bytree': 0.8552119493035586, 'gamma': 3.180427088418656, 'reg_alpha': 5.264272325370648, 'reg_lambda': 9.733461249605206}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:44:19,443] Trial 5 finished with value: 62901.80929152431 and parameters: {'learning_rate': 0.012438566317055082, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.5692421123836555, 'colsample_bytree': 0.746867801522286, 'gamma': 1.361021404616118, 'reg_alpha': 8.613087588474555, 'reg_lambda': 8.040093287062037}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:45:43,054] Trial 6 finished with value: 62580.896908525676 and parameters: {'learning_rate': 0.010849987743254571, 'max_depth': 11, 'min_child_weight': 8, 'subsample': 0.6564765031594143, 'colsample_bytree': 0.6083286844366221, 'gamma': 2.3369539392965564, 'reg_alpha': 3.4314100027426466, 'reg_lambda': 8.178378577153778}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:46:30,508] Trial 7 finished with value: 63255.268033332424 and parameters: {'learning_rate': 0.015205266330058032, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.8985078763273368, 'colsample_bytree': 0.7866155893523474, 'gamma': 2.2030486203988273, 'reg_alpha': 4.3072512996644, 'reg_lambda': 3.887037515818552}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:47:01,181] Trial 8 finished with value: 63956.95432626601 and parameters: {'learning_rate': 0.09117831620683609, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.7615462482978688, 'colsample_bytree': 0.8687203309969489, 'gamma': 3.4553412655231357, 'reg_alpha': 2.429011436742272, 'reg_lambda': 9.3382843500593}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:47:49,020] Trial 9 finished with value: 62583.077478885716 and parameters: {'learning_rate': 0.022948142152562263, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.691202697280909, 'colsample_bytree': 0.8962268504898665, 'gamma': 3.1691963782568773, 'reg_alpha': 5.927873080388933, 'reg_lambda': 3.305395998166798}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:48:29,431] Trial 10 finished with value: 63629.8608293799 and parameters: {'learning_rate': 0.03226145044814579, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5192281811104205, 'colsample_bytree': 0.5194665246574748, 'gamma': 4.610541651414053, 'reg_alpha': 0.19917187686363924, 'reg_lambda': 0.11120135416836563}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:49:47,056] Trial 11 finished with value: 62811.85117475534 and parameters: {'learning_rate': 0.01079486720840523, 'max_depth': 11, 'min_child_weight': 9, 'subsample': 0.6733937776979109, 'colsample_bytree': 0.6331562890850939, 'gamma': 0.0647007391202875, 'reg_alpha': 1.8910983622313693, 'reg_lambda': 6.168348169365544}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:50:49,855] Trial 12 finished with value: 62804.66411326593 and parameters: {'learning_rate': 0.01748088987474166, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.6192712097658332, 'colsample_bytree': 0.5886766360427569, 'gamma': 1.1813847961840303, 'reg_alpha': 2.3303233355172273, 'reg_lambda': 5.645417931135693}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:51:16,374] Trial 13 finished with value: 63566.731250529265 and parameters: {'learning_rate': 0.038820759951969194, 'max_depth': 12, 'min_child_weight': 4, 'subsample': 0.6235768934545878, 'colsample_bytree': 0.6977508210467813, 'gamma': 4.886866281536673, 'reg_alpha': 0.051219753885285435, 'reg_lambda': 2.6557880585620715}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:52:38,288] Trial 14 finished with value: 62543.07573765561 and parameters: {'learning_rate': 0.010156624371297997, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.729551365755944, 'colsample_bytree': 0.5734497538273022, 'gamma': 1.145923185468257, 'reg_alpha': 3.3602988716530313, 'reg_lambda': 6.837069126671514}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:53:31,455] Trial 15 finished with value: 62737.211477635894 and parameters: {'learning_rate': 0.016430584674475085, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.7357570680650972, 'colsample_bytree': 0.5338808627684017, 'gamma': 0.9047372075340391, 'reg_alpha': 1.4058380173392553, 'reg_lambda': 4.771201679610859}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:54:30,305] Trial 16 finished with value: 62523.65866688531 and parameters: {'learning_rate': 0.020694359972520816, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.8443293098316412, 'colsample_bytree': 0.5717565244782651, 'gamma': 0.6955501460276675, 'reg_alpha': 7.541427188892095, 'reg_lambda': 6.766838362996306}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:55:24,158] Trial 17 finished with value: 62524.05873727565 and parameters: {'learning_rate': 0.02120471013605342, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.8336070697939592, 'colsample_bytree': 0.6909471963158684, 'gamma': 0.4678542957009517, 'reg_alpha': 9.281327706150966, 'reg_lambda': 1.9235569731337399}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:55:54,515] Trial 18 finished with value: 63500.90730926445 and parameters: {'learning_rate': 0.042845710104497864, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8489864214729889, 'colsample_bytree': 0.5552472232967148, 'gamma': 1.7365025581911988, 'reg_alpha': 7.5822762483990696, 'reg_lambda': 4.4256738581792225}. Best is trial 0 with value: 62496.861326348095.\n",
      "[I 2025-11-29 19:56:47,556] Trial 19 finished with value: 62597.589160143594 and parameters: {'learning_rate': 0.014235938000866226, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.7978073738870399, 'colsample_bytree': 0.6566559140120517, 'gamma': 0.6328656767015971, 'reg_alpha': 7.8965181371597115, 'reg_lambda': 0.6605361977877076}. Best is trial 0 with value: 62496.861326348095.\n",
      "   –õ—É—á—à–∏–π WMAE: 62496.86\n",
      "   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {'learning_rate': 0.011633529763994796, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.8382566043855415, 'colsample_bytree': 0.6868297542668472, 'gamma': 0.1559836220866534, 'reg_alpha': 2.3039910053801957, 'reg_lambda': 1.7440519502839336}\n",
      "\n",
      "‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'best_params_optuna.pkl'\n"
     ]
    }
   ],
   "source": [
    "# –ë–õ–û–ö 3: BAYESIAN OPTIMIZATION\n",
    "\n",
    "# ==================================================================================\n",
    "# BAYESIAN OPTIMIZATION –î–õ–Ø –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\nüîç BAYESIAN OPTIMIZATION (50 –∏—Ç–µ—Ä–∞—Ü–∏–π –Ω–∞ –º–æ–¥–µ–ª—å)...\")\n",
    "print(\"–≠—Ç–æ –∑–∞–π–º—ë—Ç ~30-60 –º–∏–Ω—É—Ç, –Ω–æ –Ω–∞–π–¥—ë—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã!\\n\")\n",
    "\n",
    "kf_optuna = KFold(n_splits=3, shuffle=True, random_state=42)  # –ú–µ–Ω—å—à–µ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n",
    "\n",
    "# ===== CATBOOST OPTIMIZATION =====\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 1500, 3000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 8),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('random_strength', 0, 5),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "        'task_type': 'GPU',\n",
    "        'devices': '0',\n",
    "        'loss_function': 'RMSE',  # –ë–ª–∏–∂–µ –∫ WMAE\n",
    "        'verbose': 0,\n",
    "        'random_seed': 42,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, val_idx in kf_optuna.split(X_final):\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(\n",
    "            X_final.iloc[train_idx], y_log.iloc[train_idx],\n",
    "            sample_weight=w.iloc[train_idx],\n",
    "            cat_features=cat_final,\n",
    "            eval_set=(X_final.iloc[val_idx], y_log.iloc[val_idx]),\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=0\n",
    "        )\n",
    "        pred = np.expm1(model.predict(X_final.iloc[val_idx]))\n",
    "        true = np.expm1(y_log.iloc[val_idx])\n",
    "        wmae = wmae_metric(true, pred, w.iloc[val_idx])\n",
    "        scores.append(wmae)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "print(\"üê± –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è CatBoost...\")\n",
    "study_cb = optuna.create_study(direction='minimize', study_name='catboost')\n",
    "study_cb.optimize(objective_catboost, n_trials=20, show_progress_bar=True)\n",
    "best_params_cb = study_cb.best_params\n",
    "print(f\"   –õ—É—á—à–∏–π WMAE: {study_cb.best_value:.2f}\")\n",
    "print(f\"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {best_params_cb}\\n\")\n",
    "\n",
    "# ===== LIGHTGBM OPTIMIZATION =====\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'objective': 'mae',  # MAE –≤–º–µ—Å—Ç–æ regression\n",
    "        'metric': 'mae',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 127),\n",
    "        'max_depth': trial.suggest_int('max_depth', 8, 15),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 0.9),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 0.9),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),\n",
    "        'verbose': -1,\n",
    "        'seed': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, val_idx in kf_optuna.split(X_lgb):\n",
    "        train_data = lgb.Dataset(X_lgb.iloc[train_idx], y_log.iloc[train_idx], \n",
    "                                  weight=w.iloc[train_idx])\n",
    "        val_data = lgb.Dataset(X_lgb.iloc[val_idx], y_log.iloc[val_idx], \n",
    "                                weight=w.iloc[val_idx], reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params, train_data, \n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[val_data],\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        pred = np.expm1(model.predict(X_lgb.iloc[val_idx]))\n",
    "        true = np.expm1(y_log.iloc[val_idx])\n",
    "        wmae = wmae_metric(true, pred, w.iloc[val_idx])\n",
    "        scores.append(wmae)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "print(\"üí° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è LightGBM...\")\n",
    "study_lgb = optuna.create_study(direction='minimize', study_name='lightgbm')\n",
    "study_lgb.optimize(objective_lgb, n_trials=20, show_progress_bar=True)\n",
    "best_params_lgb = study_lgb.best_params\n",
    "print(f\"   –õ—É—á—à–∏–π WMAE: {study_lgb.best_value:.2f}\")\n",
    "print(f\"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {best_params_lgb}\\n\")\n",
    "\n",
    "# ===== XGBOOST OPTIMIZATION =====\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:absoluteerror',  # MAE\n",
    "        'eval_metric': 'mae',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 12),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.9),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, val_idx in kf_optuna.split(X_xgb):\n",
    "        dtrain = xgb.DMatrix(X_xgb.iloc[train_idx], label=y_log.iloc[train_idx], \n",
    "                              weight=w.iloc[train_idx])\n",
    "        dval = xgb.DMatrix(X_xgb.iloc[val_idx], label=y_log.iloc[val_idx], \n",
    "                            weight=w.iloc[val_idx])\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params, dtrain,\n",
    "            num_boost_round=2000,\n",
    "            evals=[(dval, 'val')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        pred = np.expm1(model.predict(dval))\n",
    "        true = np.expm1(y_log.iloc[val_idx])\n",
    "        wmae = wmae_metric(true, pred, w.iloc[val_idx])\n",
    "        scores.append(wmae)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "print(\"‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è XGBoost...\")\n",
    "study_xgb = optuna.create_study(direction='minimize', study_name='xgboost')\n",
    "study_xgb.optimize(objective_xgb, n_trials=20, show_progress_bar=True)\n",
    "best_params_xgb = study_xgb.best_params\n",
    "print(f\"   –õ—É—á—à–∏–π WMAE: {study_xgb.best_value:.2f}\")\n",
    "print(f\"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {best_params_xgb}\\n\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "best_params = {\n",
    "    'catboost': best_params_cb,\n",
    "    'lightgbm': best_params_lgb,\n",
    "    'xgboost': best_params_xgb\n",
    "}\n",
    "\n",
    "with open('best_params_optuna.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "print(\"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'best_params_optuna.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e89a0d4c-20dd-4229-9f68-d7124d7f5fb9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ 5-FOLD CV –° BAGGING (3 seeds –Ω–∞ –º–æ–¥–µ–ª—å)...\n",
      "–≠—Ç–æ —Å–æ–∑–¥–∞—Å—Ç OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å—Ç–µ–∫–∏–Ω–≥–∞\n",
      "\n",
      "\n",
      "============================================================\n",
      "FOLD 1/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CatBoost WMAE: 66717.08\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1672]\tvalid_0's l1: 0.417433\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1165]\tvalid_0's l1: 0.418308\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1515]\tvalid_0's l1: 0.41677\n",
      "   LightGBM WMAE: 64511.36\n",
      "   XGBoost  WMAE: 64690.39\n",
      "\n",
      "============================================================\n",
      "FOLD 2/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CatBoost WMAE: 62232.52\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's l1: 0.412952\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1414]\tvalid_0's l1: 0.413939\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1476]\tvalid_0's l1: 0.413023\n",
      "   LightGBM WMAE: 59845.30\n",
      "   XGBoost  WMAE: 60295.44\n",
      "\n",
      "============================================================\n",
      "FOLD 3/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CatBoost WMAE: 65007.14\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1716]\tvalid_0's l1: 0.416757\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tvalid_0's l1: 0.415826\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1977]\tvalid_0's l1: 0.416445\n",
      "   LightGBM WMAE: 62021.25\n",
      "   XGBoost  WMAE: 62638.94\n",
      "\n",
      "============================================================\n",
      "FOLD 4/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CatBoost WMAE: 61617.61\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1514]\tvalid_0's l1: 0.40747\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1794]\tvalid_0's l1: 0.407856\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1532]\tvalid_0's l1: 0.405734\n",
      "   LightGBM WMAE: 58852.68\n",
      "   XGBoost  WMAE: 59330.19\n",
      "\n",
      "============================================================\n",
      "FOLD 5/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CatBoost WMAE: 65087.33\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1079]\tvalid_0's l1: 0.421079\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1714]\tvalid_0's l1: 0.420828\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1352]\tvalid_0's l1: 0.421371\n",
      "   LightGBM WMAE: 62995.74\n",
      "   XGBoost  WMAE: 63023.68\n",
      "\n",
      "============================================================\n",
      "üìä –ò–¢–û–ì–û–í–´–ï CV –ú–ï–¢–†–ò–ö–ò (WMAE):\n",
      "   CatBoost:  64132.34 ¬± 1912.66\n",
      "   LightGBM:  61645.26 ¬± 2060.00\n",
      "   XGBoost:   61995.73 ¬± 1935.34\n",
      "============================================================\n",
      "\n",
      "‚úÖ OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'stacking_predictions.pkl'\n"
     ]
    }
   ],
   "source": [
    "# –ë–õ–û–ö 4: BAGGING –° –†–ê–ó–ù–´–ú–ò SEEDS + OOF –î–õ–Ø –°–¢–ï–ö–ò–ù–ì–ê\n",
    "\n",
    "# ==================================================================================\n",
    "# –û–ë–£–ß–ï–ù–ò–ï –° BAGGING (3 SEEDS) + OUT-OF-FOLD –î–õ–Ø –°–¢–ï–ö–ò–ù–ì–ê\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\nüîÑ 5-FOLD CV –° BAGGING (3 seeds –Ω–∞ –º–æ–¥–µ–ª—å)...\")\n",
    "print(\"–≠—Ç–æ —Å–æ–∑–¥–∞—Å—Ç OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å—Ç–µ–∫–∏–Ω–≥–∞\\n\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "with open('best_params_optuna.pkl', 'rb') as f:\n",
    "    best_params = pickle.load(f)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å—Ç–µ–∫–∏–Ω–≥–∞\n",
    "oof_cb = np.zeros(len(X_final))\n",
    "oof_lgb = np.zeros(len(X_final))\n",
    "oof_xgb = np.zeros(len(X_final))\n",
    "\n",
    "# –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—É—Å—Ä–µ–¥–Ω–∏–º –ø–æ seeds –∏ —Ñ–æ–ª–¥–∞–º)\n",
    "test_preds_cb = np.zeros(len(X_test_final))\n",
    "test_preds_lgb = np.zeros(len(X_test_lgb))\n",
    "test_preds_xgb = np.zeros(len(X_test_xgb))\n",
    "\n",
    "cv_scores_cb = []\n",
    "cv_scores_lgb = []\n",
    "cv_scores_xgb = []\n",
    "\n",
    "BAGGING_SEEDS = [42, 123, 777]  # 3 —Ä–∞–∑–Ω—ã—Ö seed –¥–ª—è bagging\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_final)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold+1}/5\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    X_tr, X_val = X_final.iloc[train_idx], X_final.iloc[val_idx]\n",
    "    y_tr, y_val = y_log.iloc[train_idx], y_log.iloc[val_idx]\n",
    "    w_tr, w_val = w.iloc[train_idx], w.iloc[val_idx]\n",
    "    \n",
    "    val_true = np.expm1(y_val)\n",
    "    \n",
    "    # ===== CATBOOST —Å BAGGING =====\n",
    "    preds_cb_seeds = []\n",
    "    test_cb_seeds = []\n",
    "    \n",
    "    for seed in BAGGING_SEEDS:\n",
    "        params_cb = best_params['catboost'].copy()\n",
    "        params_cb.update({\n",
    "            'task_type': 'GPU',\n",
    "            'devices': '0',\n",
    "            'loss_function': 'MAE',\n",
    "            'verbose': 0,\n",
    "            'random_seed': seed,\n",
    "            'allow_writing_files': False\n",
    "        })\n",
    "        \n",
    "        model = CatBoostRegressor(**params_cb)\n",
    "        model.fit(\n",
    "            X_tr, y_tr, sample_weight=w_tr,\n",
    "            cat_features=cat_final,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        val_pred = np.expm1(model.predict(X_val))\n",
    "        test_pred = np.expm1(model.predict(X_test_final))\n",
    "        \n",
    "        preds_cb_seeds.append(val_pred)\n",
    "        test_cb_seeds.append(test_pred)\n",
    "    \n",
    "    # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ seeds\n",
    "    oof_cb[val_idx] = np.mean(preds_cb_seeds, axis=0)\n",
    "    test_preds_cb += np.mean(test_cb_seeds, axis=0) / 5\n",
    "    \n",
    "    wmae_cb = wmae_metric(val_true, oof_cb[val_idx], w_val)\n",
    "    cv_scores_cb.append(wmae_cb)\n",
    "    print(f\"   CatBoost WMAE: {wmae_cb:.2f}\")\n",
    "    \n",
    "    # ===== LIGHTGBM —Å BAGGING =====\n",
    "    preds_lgb_seeds = []\n",
    "    test_lgb_seeds = []\n",
    "    \n",
    "    for seed in BAGGING_SEEDS:\n",
    "        params_lgb = best_params['lightgbm'].copy()\n",
    "        params_lgb.update({\n",
    "            'objective': 'mae',\n",
    "            'metric': 'mae',\n",
    "            'verbose': -1,\n",
    "            'seed': seed,\n",
    "            'n_jobs': -1\n",
    "        })\n",
    "        \n",
    "        train_data = lgb.Dataset(X_lgb.iloc[train_idx], y_tr, weight=w_tr)\n",
    "        val_data = lgb.Dataset(X_lgb.iloc[val_idx], y_val, weight=w_val, reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params_lgb, train_data,\n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[val_data],\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        val_pred = np.expm1(model.predict(X_lgb.iloc[val_idx]))\n",
    "        test_pred = np.expm1(model.predict(X_test_lgb))\n",
    "        \n",
    "        preds_lgb_seeds.append(val_pred)\n",
    "        test_lgb_seeds.append(test_pred)\n",
    "    \n",
    "    oof_lgb[val_idx] = np.mean(preds_lgb_seeds, axis=0)\n",
    "    test_preds_lgb += np.mean(test_lgb_seeds, axis=0) / 5\n",
    "    \n",
    "    wmae_lgb = wmae_metric(val_true, oof_lgb[val_idx], w_val)\n",
    "    cv_scores_lgb.append(wmae_lgb)\n",
    "    print(f\"   LightGBM WMAE: {wmae_lgb:.2f}\")\n",
    "    \n",
    "    # ===== XGBOOST —Å BAGGING =====\n",
    "    preds_xgb_seeds = []\n",
    "    test_xgb_seeds = []\n",
    "    \n",
    "    for seed in BAGGING_SEEDS:\n",
    "        params_xgb = best_params['xgboost'].copy()\n",
    "        params_xgb.update({\n",
    "            'objective': 'reg:absoluteerror',\n",
    "            'eval_metric': 'mae',\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'seed': seed\n",
    "        })\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_xgb.iloc[train_idx], label=y_tr, weight=w_tr)\n",
    "        dval = xgb.DMatrix(X_xgb.iloc[val_idx], label=y_val, weight=w_val)\n",
    "        dtest = xgb.DMatrix(X_test_xgb)\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params_xgb, dtrain,\n",
    "            num_boost_round=2000,\n",
    "            evals=[(dval, 'val')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        val_pred = np.expm1(model.predict(dval))\n",
    "        test_pred = np.expm1(model.predict(dtest))\n",
    "        \n",
    "        preds_xgb_seeds.append(val_pred)\n",
    "        test_xgb_seeds.append(test_pred)\n",
    "    \n",
    "    oof_xgb[val_idx] = np.mean(preds_xgb_seeds, axis=0)\n",
    "    test_preds_xgb += np.mean(test_xgb_seeds, axis=0) / 5\n",
    "    \n",
    "    wmae_xgb = wmae_metric(val_true, oof_xgb[val_idx], w_val)\n",
    "    cv_scores_xgb.append(wmae_xgb)\n",
    "    print(f\"   XGBoost  WMAE: {wmae_xgb:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä –ò–¢–û–ì–û–í–´–ï CV –ú–ï–¢–†–ò–ö–ò (WMAE):\")\n",
    "print(f\"   CatBoost:  {np.mean(cv_scores_cb):.2f} ¬± {np.std(cv_scores_cb):.2f}\")\n",
    "print(f\"   LightGBM:  {np.mean(cv_scores_lgb):.2f} ¬± {np.std(cv_scores_lgb):.2f}\")\n",
    "print(f\"   XGBoost:   {np.mean(cv_scores_xgb):.2f} ¬± {np.std(cv_scores_xgb):.2f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º OOF –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "stacking_data = {\n",
    "    'oof_cb': oof_cb,\n",
    "    'oof_lgb': oof_lgb,\n",
    "    'oof_xgb': oof_xgb,\n",
    "    'test_preds_cb': test_preds_cb,\n",
    "    'test_preds_lgb': test_preds_lgb,\n",
    "    'test_preds_xgb': test_preds_xgb,\n",
    "    'y_log': y_log,\n",
    "    'w': w,\n",
    "    'cv_scores_cb': cv_scores_cb,\n",
    "    'cv_scores_lgb': cv_scores_lgb,\n",
    "    'cv_scores_xgb': cv_scores_xgb\n",
    "}\n",
    "\n",
    "with open('stacking_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(stacking_data, f)\n",
    "\n",
    "print(\"\\n‚úÖ OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'stacking_predictions.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec8e2f6f-6bfe-43fd-8b53-d28661b728a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèóÔ∏è –°–¢–ï–ö–ò–ù–ì: –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏...\n",
      "   –û–±—É—á–µ–Ω–∏–µ Ridge —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...\n",
      "   –°—Ç–µ–∫–∏–Ω–≥ WMAE (train): 67809.73\n",
      "\n",
      "   –í–µ—Å–∞ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏:\n",
      "      CatBoost:  0.096\n",
      "      LightGBM:  0.694\n",
      "      XGBoost:   0.312\n",
      "\n",
      "‚úÖ –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ 'meta_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# –ë–õ–û–ö 5: –°–¢–ï–ö–ò–ù–ì ‚Äî –ú–ï–¢–ê-–ú–û–î–ï–õ–¨\n",
    "\n",
    "# ==================================================================================\n",
    "# –°–¢–ï–ö–ò–ù–ì: –û–ë–£–ß–ï–ù–ò–ï –ú–ï–¢–ê-–ú–û–î–ï–õ–ò\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\nüèóÔ∏è –°–¢–ï–ö–ò–ù–ì: –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏...\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º OOF –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "with open('stacking_predictions.pkl', 'rb') as f:\n",
    "    stack_data = pickle.load(f)\n",
    "\n",
    "oof_cb = stack_data['oof_cb']\n",
    "oof_lgb = stack_data['oof_lgb']\n",
    "oof_xgb = stack_data['oof_xgb']\n",
    "test_preds_cb = stack_data['test_preds_cb']\n",
    "test_preds_lgb = stack_data['test_preds_lgb']\n",
    "test_preds_xgb = stack_data['test_preds_xgb']\n",
    "y_log = stack_data['y_log']\n",
    "w = stack_data['w']\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º —Ñ–∏—á–∏ –¥–ª—è –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏\n",
    "X_meta_train = np.column_stack([oof_cb, oof_lgb, oof_xgb])\n",
    "X_meta_test = np.column_stack([test_preds_cb, test_preds_lgb, test_preds_xgb])\n",
    "\n",
    "y_meta = np.expm1(y_log)\n",
    "\n",
    "# –û–±—É—á–∞–µ–º –º–µ—Ç–∞-–º–æ–¥–µ–ª—å (Ridge —Å –≤–µ—Å–∞–º–∏)\n",
    "print(\"   –û–±—É—á–µ–Ω–∏–µ Ridge —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...\")\n",
    "meta_model = Ridge(alpha=10, random_state=42)\n",
    "meta_model.fit(X_meta_train, y_meta, sample_weight=w)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏\n",
    "meta_train_pred = meta_model.predict(X_meta_train)\n",
    "meta_test_pred = meta_model.predict(X_meta_test)\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∞ —Å—Ç–µ–∫–∏–Ω–≥–∞\n",
    "wmae_stacking = wmae_metric(y_meta, meta_train_pred, w)\n",
    "print(f\"   –°—Ç–µ–∫–∏–Ω–≥ WMAE (train): {wmae_stacking:.2f}\")\n",
    "\n",
    "# –í–µ—Å–∞ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏\n",
    "weights_meta = meta_model.coef_\n",
    "print(f\"\\n   –í–µ—Å–∞ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏:\")\n",
    "print(f\"      CatBoost:  {weights_meta[0]:.3f}\")\n",
    "print(f\"      LightGBM:  {weights_meta[1]:.3f}\")\n",
    "print(f\"      XGBoost:   {weights_meta[2]:.3f}\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞-–º–æ–¥–µ–ª—å\n",
    "with open('meta_model.pkl', 'wb') as f:\n",
    "    pickle.dump(meta_model, f)\n",
    "\n",
    "print(\"\\n‚úÖ –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ 'meta_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddbb8c1f-b26f-4621-92e3-fd0d704e57d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ –§–ò–ù–ê–õ–¨–ù–´–ô –≠–ö–°–ü–û–†–¢...\n",
      "‚úÖ submission_ULTIMATE_stacking.csv\n",
      "   min=37495, max=1205766, mean=117361\n",
      "\n",
      "‚úÖ submission_ULTIMATE_blend.csv\n",
      "   min=20098, max=1096094, mean=92774\n",
      "\n",
      "üéâ –í–°–Å –ì–û–¢–û–í–û! –£ —Ç–µ–±—è —Ç–µ–ø–µ—Ä—å –¢–û–ü-–£–†–û–í–ï–ù–¨ ML —Å–∏—Å—Ç–µ–º–∞!\n"
     ]
    }
   ],
   "source": [
    "# –ë–õ–û–ö 6: –§–ò–ù–ê–õ–¨–ù–´–ô –≠–ö–°–ü–û–†–¢\n",
    "\n",
    "# ==================================================================================\n",
    "# –§–ò–ù–ê–õ–¨–ù–´–ô –≠–ö–°–ü–û–†–¢\n",
    "# ==================================================================================\n",
    "\n",
    "print(\"\\nüèÜ –§–ò–ù–ê–õ–¨–ù–´–ô –≠–ö–°–ü–û–†–¢...\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å—ë –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ\n",
    "with open('data_checkpoint.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    test_ids = data['test_ids']\n",
    "\n",
    "with open('stacking_predictions.pkl', 'rb') as f:\n",
    "    preds = pickle.load(f)\n",
    "    test_preds_cb = preds['test_preds_cb']\n",
    "    test_preds_lgb = preds['test_preds_lgb']\n",
    "    test_preds_xgb = preds['test_preds_xgb']\n",
    "\n",
    "with open('meta_model.pkl', 'rb') as f:\n",
    "    meta_model = pickle.load(f)\n",
    "\n",
    "# –°—Ç–µ–∫–∏–Ω–≥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "X_meta_test = np.column_stack([test_preds_cb, test_preds_lgb, test_preds_xgb])\n",
    "final_preds_stacking = meta_model.predict(X_meta_test)\n",
    "final_preds_stacking = np.clip(final_preds_stacking, 20000, None)\n",
    "\n",
    "# –ü—Ä–æ—Å—Ç–æ–π –±–ª–µ–Ω–¥–∏–Ω–≥ (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)\n",
    "final_preds_blend = 0.3 * test_preds_cb + 0.5 * test_preds_lgb + 0.2 * test_preds_xgb\n",
    "final_preds_blend = np.clip(final_preds_blend, 20000, None)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞\n",
    "submissions = {\n",
    "    'stacking': final_preds_stacking,\n",
    "    'blend': final_preds_blend\n",
    "}\n",
    "\n",
    "for name, preds in submissions.items():\n",
    "    sub = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'predict': preds\n",
    "    })\n",
    "    \n",
    "    filename = f'submission_ULTIMATE_{name}.csv'\n",
    "    sub.to_csv(filename, sep=',', index=False, float_format='%.2f')\n",
    "    \n",
    "    print(f\"‚úÖ {filename}\")\n",
    "    print(f\"   min={preds.min():.0f}, max={preds.max():.0f}, mean={preds.mean():.0f}\\n\")\n",
    "\n",
    "print(\"üéâ –í–°–Å –ì–û–¢–û–í–û! –£ —Ç–µ–±—è —Ç–µ–ø–µ—Ä—å –¢–û–ü-–£–†–û–í–ï–ù–¨ ML —Å–∏—Å—Ç–µ–º–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "602f60da-5ceb-4c63-b625-c4716a623094",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è API...\n",
      "‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è API!\n"
     ]
    }
   ],
   "source": [
    "# --- –î–û–ë–ê–í–ò–¢–¨ –≠–¢–û –í –ö–û–ù–ï–¶ –ù–û–£–¢–ë–£–ö–ê ---\n",
    "import joblib\n",
    "\n",
    "# 1. –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –í–°–ï–• –¥–∞–Ω–Ω—ã—Ö (X_final)\n",
    "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è API...\")\n",
    "\n",
    "# CatBoost\n",
    "final_cb = CatBoostRegressor(**best_params['catboost'])\n",
    "final_cb.fit(X_final, y_log, sample_weight=w, cat_features=cat_final, verbose=0)\n",
    "final_cb.save_model(\"catboost_final.cbm\") # CatBoost —Å–≤–æ–π —Ñ–æ—Ä–º–∞—Ç –ª—é–±–∏—Ç\n",
    "\n",
    "# LightGBM\n",
    "train_data_lgb = lgb.Dataset(X_lgb, y_log, weight=w)\n",
    "final_lgb = lgb.train(best_params['lightgbm'], train_data_lgb, num_boost_round=2000)\n",
    "joblib.dump(final_lgb, \"lightgbm_final.pkl\")\n",
    "\n",
    "# XGBoost\n",
    "dtrain_all = xgb.DMatrix(X_xgb, label=y_log, weight=w)\n",
    "final_xgb = xgb.train(best_params['xgboost'], dtrain_all, num_boost_round=2000)\n",
    "joblib.dump(final_xgb, \"xgboost_final.pkl\")\n",
    "\n",
    "# Meta model (Ridge) —É–∂–µ —É —Ç–µ–±—è –µ—Å—Ç—å - meta_model.pkl\n",
    "# –¢–∞–∫–∂–µ –Ω–∞–º –Ω—É–∂–µ–Ω —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫, —á—Ç–æ–±—ã API –∑–Ω–∞–ª –ø–æ—Ä—è–¥–æ–∫\n",
    "cols_info = {\n",
    "    \"cat_features\": cat_final,\n",
    "    \"all_columns\": list(X_final.columns)\n",
    "}\n",
    "joblib.dump(cols_info, \"columns_info.pkl\")\n",
    "\n",
    "print(\"‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è API!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
